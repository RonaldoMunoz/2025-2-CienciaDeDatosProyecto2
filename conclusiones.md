# Proyecto 2 y 3: Introducci√≥n a la ciencia de datos.


- Michael Rodriguez Arana
- Yeifer Ronaldo Mu√±oz Valencia
- Juan Carlos Rojas Quintero

#### HALLAZGOS OBTENIDOS

### ANALISIS DESCRIPTIVO DEL DATASET

En la primera parte del proyecto nos encontramos con el analicis descriptivo del dataset, donde se cargo el dataset en python usando pandas y se generaron visualizaciones exploratorias con Matplotlib y Seaborn

Primeramnete se realiz√≥ una adecuada carga y preparaci√≥n del conjunto de datos avocado.csv, eliminando columnas innecesarias como Unnamed: 0 y convirtiendo el campo Date a un formato de fecha reconocible por Python. Este proceso permiti√≥ garantizar la coherencia y calidad de los datos antes del an√°lisis exploratorio,

## Gr√°fico 1: Distribuci√≥n del Precio Promedio

El histograma evidenci√≥ que la mayor√≠a de los precios del aguacate se concentran entre 1.00 y 1.50 USD, con pocos casos que superan los 2.00 USD. La distribuci√≥n presenta un sesgo positivo, lo cual indica que existen registros con precios m√°s altos, aunque poco frecuentes. Esta caracter√≠stica podr√≠a influir en modelos predictivos o comparativos, por lo que se recomienda considerar normalizaci√≥n o transformaciones estad√≠sticas en etapas posteriores.

## Gr√°fico 2: Comparaci√≥n de Precios por Tipo de Aguacate

El diagrama de caja mostr√≥ que los aguacates org√°nicos tienen un precio promedio significativamente mayor que los convencionales. Adem√°s, presentan una mayor variabilidad y m√°s valores at√≠picos (outliers), lo que refleja la inestabilidad del mercado de productos org√°nicos y la influencia de factores externos como la demanda o la disponibilidad.
Por otro lado, los aguacates convencionales exhiben precios m√°s estables y concentrados, lo cual sugiere una oferta m√°s constante y una menor sensibilidad a cambios de mercado.

## Gr√°fico 3: Mapa de Calor de Correlaci√≥n de Variables Num√©ricas

El mapa de calor permiti√≥ identificar correlaciones significativas dentro del dataset.

Se observ√≥ una fuerte correlaci√≥n positiva (‚âà 0.97 a 0.99) entre las variables relacionadas con el volumen y las diferentes categor√≠as de bolsas (Total Volume, 4046, 4225, Total Bags, etc.), lo que indica que los aumentos en el volumen total de ventas est√°n estrechamente vinculados al incremento en la cantidad de unidades vendidas por tipo.

En cambio, el precio promedio (AveragePrice) presenta una correlaci√≥n negativa moderada con el volumen total (-0.19), sugiriendo que, en general, a mayor volumen de ventas, menor precio promedio, lo cual concuerda con la l√≥gica de oferta y demanda del mercado.

## Gr√°fico 4: Evoluci√≥n del Precio Promedio (2015-2018)

La serie temporal de precios promedio entre 2015 y 2018 evidencia una variaci√≥n estacional y c√≠clica. Se observan incrementos pronunciados en ciertos periodos, especialmente hacia mediados de 2017, donde los precios alcanzaron su punto m√°ximo cercano a $1.85 USD. Posteriormente, se produce una tendencia descendente. Este comportamiento podr√≠a explicarse por fluctuaciones en la producci√≥n, la exportaci√≥n o la estacionalidad del cultivo del aguacate.

## Gr√°fico 5: Distribuci√≥n de Variables de Volumen (Datos Crudos)

Vemos la frecuencia de las ventas. Todos los gr√°ficos est√°n "aplastados" contra la izquierda, esto indica que la mayor√≠a de las ventas son de volumen bajo/medio, pero existen unos pocos valores at√≠pico de ventas masivas que distorsionan toda la escala, los modelos de regresi√≥n lineal funcionan muy mal con datos tan sesgados, por lo tanto debemos transformar estos datos.

## Gr√°fico 6: Distribuci√≥n de Variables de Volumen (Log-Transformadas)

Los mismos histogramas del Gr√°fico anterior, pero despu√©s de aplicarles una transformaci√≥n logar√≠tmica, al aplicar el logaritmo, la escala se "comprime". Las distribuciones que antes estaban aplastadas ahora se asemejan mucho m√°s a una distribuci√≥n normal. Los outliers ya no dominan el gr√°fico, esto nos ayuda a entender que en la fase 2 no debemos eliminar estos valores atipicos que son ventas reales, sino que debemos aplicarles una transformaci√≥n logaritmica.


### LIMPIEZA Y NORMALIZACION DE DATOS

Donde primeramente en esta parte del proceso se realiz√≥ la transformaci√≥n de la variable temporal ‚ÄúDate‚Äù con el fin de hacerla √∫til para el an√°lisis y los modelos de aprendizaje autom√°tico. 
Primero, la columna Date fue convertida al tipo de dato datetime, lo que permiti√≥ extraer informaci√≥n temporal relevante. A partir de ella, se generaron cuatro nuevas variables num√©ricas:
 - year_date: representa el a√±o.
 - month: indica el mes (de 1 a 12).
 - day: muestra el d√≠a del mes.
 - week: corresponde al n√∫mero de la semana del a√±o seg√∫n el calendario ISO.

Finalmente, se elimin√≥ la columna original Date, ya que su formato de texto no es directamente interpretable por los modelos.
En conclusi√≥n, esta conversi√≥n permiti√≥ incorporar la dimensi√≥n temporal en forma num√©rica, facilitando la detecci√≥n de patrones estacionales, tendencias o variaciones a lo largo del tiempo, algo esencial para mejorar el rendimiento y la interpretaci√≥n de los modelos predictivos.

## Revisi√≥n y tratamiento de valores nulos dentro del conjunto de datos.

Primero, mediante la instrucci√≥n df.isna().sum(), se verific√≥ la presencia de valores faltantes en cada columna, encontr√°ndose que no exist√≠an datos nulos, sin embargo, para garantizar la consistencia y robustez del preprocesamiento, se aplic√≥ una regla general de imputaci√≥n preventiva en caso de que aparezcan valores faltantes en futuras actualizaciones del dataset:
 - En variables num√©ricas, los valores nulos ser√≠an reemplazados por la mediana de la columna.
 - En variables categ√≥ricas, se usar√≠a la moda (el valor m√°s frecuente).
En conclusi√≥n, esta revisi√≥n asegura que el conjunto de datos se mantenga libre de valores faltantes y, en caso de que surjan, se impute de forma coherente, evitando errores en los modelos y manteniendo la estabilidad de los resultados anal√≠ticos.

## detecci√≥n y el tratamiento de valores at√≠picos (outliers) en las variables num√©ricas del conjunto de datos.

Para cada columna num√©rica, se calcularon los cuartiles (Q1 y Q3) y el rango intercuart√≠lico (IQR = Q3 - Q1). A partir de estos, se establecieron los l√≠mites inferior y superior para definir los valores considerados at√≠picos:
 - L√≠mite inferior: Q1 - 1.5 * IQR
 - L√≠mite superior: Q3 + 1.5 * IQR
En lugar de eliminar las observaciones extremas, se aplic√≥ una winsorizaci√≥n, es decir, se ajustaron los valores fuera de los l√≠mites hacia los valores l√≠mite m√°s cercanos:
 - Valores menores al l√≠mite inferior se reemplazaron por el propio l√≠mite inferior.
 - Valores mayores al l√≠mite superior se reemplazaron por el l√≠mite superior.
En conclusi√≥n, este procedimiento permiti√≥ reducir la influencia de valores extremos sobre los modelos estad√≠sticos o de machine learning, sin perder informaci√≥n al eliminar filas. De este modo, se preserv√≥ la integridad del conjunto de datos y se mejor√≥ la estabilidad y fiabilidad del an√°lisis posterior.

## codificaci√≥n de variables categ√≥ricas mediante el uso de variables dummy (o indicadoras).

Se aplic√≥ la funci√≥n pd.get_dummies(df, drop_first=True) sobre las columnas no num√©ricas (por ejemplo, type o region), transformando cada categor√≠a en una nueva columna binaria con valores 0 o 1, que indican la ausencia o presencia de dicha categor√≠a. El par√°metro drop_first=True se incluy√≥ para evitar la multicolinealidad en modelos de regresi√≥n, ya que elimina una de las categor√≠as de referencia por cada variable, manteniendo la informaci√≥n sin redundancias.
En conclusi√≥n, este paso permiti√≥ convertir todas las variables del conjunto de datos en formato num√©rico, requisito esencial para el entrenamiento de la mayor√≠a de los modelos de machine learning, preservando la informaci√≥n categ√≥rica de forma adecuada y estad√≠sticamente estable.

## estandarizaci√≥n de las variables predictoras

Primero, se separ√≥ la variable objetivo (AveragePrice) del conjunto de datos, ya que no debe ser transformada al representar el valor real a predecir. Luego, se identificaron las variables num√©ricas (excluyendo las dummies de regiones) que ser√≠an sometidas al proceso de escalado.
Para la estandarizaci√≥n se emple√≥ la clase StandardScaler de scikit-learn, la cual transforma cada variable restando su media y dividi√©ndola por su desviaci√≥n est√°ndar. De esta forma, todas las variables quedan con una media cercana a 0 y una desviaci√≥n est√°ndar igual a 1.
El escalador se ajust√≥ √∫nicamente con los datos de entrenamiento (X_train), evitando la fuga de informaci√≥n (data leakage) hacia el conjunto de prueba. Posteriormente, se aplic√≥ la misma transformaci√≥n tanto a X_train como a X_test, manteniendo la coherencia en la escala de los datos.

### IMPLEMENTACION DE MODELOS PREDICTIVOS

## Regresion LIneal

El proceso sigui√≥ una metodolog√≠a estructurada compuesta por las siguientes etapas:

**Carga de los datos:** se importaron los conjuntos de entrenamiento y prueba ya procesados, asegurando que todos los valores estuvieran listos para ser utilizados por el modelo.

**Separaci√≥n de variables:** se distingui√≥ la variable objetivo (AveragePrice) del conjunto de variables predictoras (X), necesarias para construir el modelo.

**Entrenamiento del modelo:** se entren√≥ un objeto de LinearRegression de la biblioteca scikit-learn, ajustando los coeficientes de la ecuaci√≥n lineal que mejor se adapta a los datos de entrenamiento.

**Evaluaci√≥n del desempe√±o:** se realizaron predicciones sobre el conjunto de prueba y se calcularon tres m√©tricas clave:

**MAE (Mean Absolute Error):** mide el error promedio absoluto.

**RMSE (Root Mean Squared Error):** penaliza los errores grandes y refleja la precisi√≥n general del modelo.

**R¬≤ (Coeficiente de determinaci√≥n):** indica qu√© proporci√≥n de la variabilidad del precio es explicada por las variables predictoras.

**An√°lisis de coeficientes:** se exportaron los coeficientes del modelo a un archivo CSV para identificar las variables con mayor influencia (positiva o negativa) sobre el precio del aguacate.

En conclusi√≥n, la Regresi√≥n Lineal permiti√≥ cuantificar la relaci√≥n entre las caracter√≠sticas del aguacate y su precio promedio, proporcionando una primera aproximaci√≥n interpretativa al problema. Este modelo sirve como l√≠nea base para comparar el desempe√±o con otros algoritmos m√°s complejos en etapas posteriores.

## Ramdom Forest Regressor

En esta secci√≥n se implement√≥ un modelo predictivo basado en Random Forest Regressor con el prop√≥sito de estimar el precio promedio del aguacate (AveragePrice) a partir de diversas variables explicativas, incluyendo tipo, regi√≥n, volumen de ventas y componentes temporales.
El dataset empleado (avocado_final_clean.csv) ya hab√≠a pasado por un proceso completo de preprocesamiento, que incluy√≥ la eliminaci√≥n de valores nulos, el tratamiento de outliers, la codificaci√≥n de variables categ√≥ricas y la estandarizaci√≥n de las variables predictoras. Esto garantiz√≥ que los datos estuvieran en condiciones √≥ptimas para el entrenamiento del modelo.
El Random Forest Regressor, perteneciente a la familia de los modelos de ensamble, combina m√∫ltiples √°rboles de decisi√≥n para mejorar la precisi√≥n y la estabilidad de las predicciones. Cada √°rbol es entrenado sobre una muestra aleatoria del conjunto de datos, y el resultado final se obtiene promediando las predicciones individuales, lo que reduce el riesgo de sobreajuste.

**Separaci√≥n de variables y la divisi√≥n del conjunto de datos** se estableci√≥ la variable objetivo (y) como el precio promedio del aguacate (AveragePrice), mientras que las variables predictoras (X) correspondieron a todas las dem√°s columnas del dataset. Esta separaci√≥n es fundamental para el entrenamiento supervisado, ya que permite que el modelo aprenda la relaci√≥n entre las caracter√≠sticas del aguacate y su precio, Posteriormente, se efectu√≥ la divisi√≥n del dataset en dos subconjuntos con el objetivo de evaluar el rendimiento del modelo de forma objetiva:

 - Conjunto de entrenamiento (80%): utilizado para ajustar los par√°metros del modelo.
 - Conjunto de prueba (20%): reservado para evaluar qu√© tan bien el modelo generaliza a datos no vistos.

La partici√≥n se realiz√≥ usando train_test_split con una semilla aleatoria (random_state=42) para garantizar la reproducibilidad de los resultados Y Finalmente, se configur√≥ el modelo RandomForestRegressor con par√°metros clave como:

 - n_estimators=200 ‚Üí n√∫mero de √°rboles en el bosque.
 - max_depth=None ‚Üí sin l√≠mite de profundidad para permitir el crecimiento completo de los √°rboles.
 - random_state=42 ‚Üí consistencia entre ejecuciones.
 - n_jobs=-1 ‚Üí uso de todos los n√∫cleos disponibles para acelerar el entrenamiento.

**Entrenamiento de modelo:** Los par√°metros empleados fueron:
 - n_estimators=200 ‚Üí n√∫mero de √°rboles en el bosque.
 - max_depth=None ‚Üí los √°rboles crecen sin l√≠mite de profundidad, lo que permite capturar relaciones complejas.
 - random_state=42 ‚Üí asegura reproducibilidad de los resultados.
 - n_jobs=-1 ‚Üí utiliza todos los n√∫cleos del procesador para acelerar el entrenamiento.
El modelo fue ajustado con los datos de entrenamiento (X_train, y_train), completando exitosamente el proceso de aprendizaje.

**Evaluacion de desempe√±o:** Una vez entrenado, el modelo fue evaluado sobre el conjunto de prueba (X_test, y_test) mediante tres m√©tricas fundamentales:
 - MAE (Mean Absolute Error): mide el error promedio absoluto entre los valores reales y las predicciones.
 - RMSE (Root Mean Squared Error): penaliza los errores grandes, reflejando la precisi√≥n general del modelo.
 - R¬≤ (Coeficiente de Determinaci√≥n): indica qu√© tan bien el modelo explica la variabilidad del precio (1 = ajuste perfecto).
Los resultados obtenidos fueron:
MAE: 0.0852
RMSE: 0.1196
R¬≤: 0.9084

El modelo revela que el tipo de aguacate es el factor clave en la determinaci√≥n del precio, seguido por las caracter√≠sticas de empaque y volumen de ventas, mientras que los factores temporales tienen una influencia secundaria pero no despreciable.
Esto sugiere que tanto las estrategias de producci√≥n (tipo de producto) como las condiciones del mercado (volumen y √©poca del a√±o) impactan directamente en el valor final del aguacate.

## Red Neuronal

En esta etapa del an√°lisis se implement√≥ un modelo de Red Neuronal Multicapa (MLPRegressor) con el objetivo de predecir el precio promedio del aguacate (AveragePrice) a partir de diversas variables predictoras como volumen total, tipo de producto, bolsas por tama√±o y datos temporales (semana, mes, a√±o).

**carga y preparaci√≥n de datos:**

Se utilizaron los archivos avocado_train_clean.csv y avocado_test_clean.csv, que ya hab√≠an sido previamente limpiados, estandarizados y codificados, Se separaron las variables predictoras (X) y la variable objetivo (y = AveragePrice), Se verific√≥ que las variables estuvieran centradas en 0, confirmando que la estandarizaci√≥n fue correcta.

**Definici√≥n y entrenamiento del modelo:**

Se implement√≥ un MLPRegressor con dos capas ocultas de tama√±os (64, 32), funci√≥n de activaci√≥n ReLU, optimizador Adam, y un m√°ximo de 1000 iteraciones, El modelo se entren√≥ con los datos de entrenamiento (X_train, y_train) hasta lograr convergencia.

**Evaluaci√≥n del desempe√±o:**

Se realizaron predicciones sobre el conjunto de prueba (X_test) y se evaluaron las m√©tricas:
MSE (Mean Squared Error): 0.0193
R¬≤ (Coeficiente de determinaci√≥n): 0.8765
Los resultados muestran un bajo error promedio cuadr√°tico y un alto nivel de explicaci√≥n (‚âà 87.6%) de la variabilidad del precio promedio del aguacate.

El modelo de Red Neuronal (MLPRegressor) logr√≥ resultados satisfactorios y consistentes, mostrando una capacidad predictiva alta (R¬≤ ‚âà 0.88) y un error bajo (MSE ‚âà 0.02).
Si bien su desempe√±o fue ligeramente inferior al Random Forest, representa un enfoque poderoso para capturar relaciones no lineales y complejas entre las variables del dataset.
Con un ajuste m√°s fino de hiperpar√°metros, es probable que iguale o incluso supere el rendimiento de los m√©todos basados en √°rboles.


#### EFECTIVIDAD DE MODELOS PREDICTIVOS Y POSIBLES MEJORAS

## Regresion LIneal

# Efectividad
El modelo de Regresi√≥n Lineal presenta un desempe√±o aceptable pero no sobresaliente:

 - Explica el 60.8% de la variabilidad en el precio.

 - Muestra errores moderados (MAE ‚âà 0.19).

 - Ofrece interpretabilidad alta, permitiendo identificar claramente la influencia de cada variable.

Sin embargo, comparado con modelos m√°s complejos como Random Forest (R¬≤ ‚âà 0.90) o Red Neuronal (R¬≤ ‚âà 0.88), su capacidad predictiva es considerablemente menor, lo que sugiere que la relaci√≥n entre las variables y el precio no es completamente lineal.

# Mejoras
 - Transformaciones de variables no lineales, Aplicar logaritmos, ra√≠ces o t√©rminos polin√≥micos (por ejemplo, TotalVolume¬≤, month¬≤) para capturar relaciones curvas, Incluir interacciones entre variables (region √ó month, type √ó volume).

 - Regularizaci√≥n, Implementar variantes de la regresi√≥n lineal como Ridge o Lasso, que pueden mejorar la generalizaci√≥n reduciendo sobreajuste.

 - Selecci√≥n de caracter√≠sticas (Feature Selection), Eliminar variables redundantes o poco relevantes y Utilizar t√©cnicas autom√°ticas como SelectKBest o Recursive Feature Elimination (RFE).

 - Modelos no lineales alternativos, Probar modelos m√°s complejos como Random Forest, Gradient Boosting o Redes Neuronales, que ya demostraron mejor rendimiento.

## Random Forest

MAE (Mean Absolute Error) : 0.0852 , En promedio, el modelo se equivoca 0.085 unidades en la predicci√≥n del precio del aguacate.
RMSE (Root Mean Squared Error) : 0.1196 , Penaliza m√°s los errores grandes; indica que las desviaciones t√≠picas de las predicciones son de ~0.12.
R¬≤ (Coeficiente de Determinaci√≥n) : 0.9084 ,  El modelo explica aproximadamente el 90.8% de la variabilidad del precio promedio del aguacate.

# Efectividad
 - El valor de R¬≤ = 0.9084 es excelente para un modelo de regresi√≥n, ya que implica que el modelo captura casi toda la relaci√≥n entre las variables predictoras y la variable objetivo.

 - Los errores (MAE y RMSE) son bajos y consistentes, lo que indica buena estabilidad y precisi√≥n.

 - En t√©rminos pr√°cticos: el modelo predice muy bien los precios del aguacate, aunque todav√≠a hay un 9% de variabilidad no explicada (posiblemente por factores externos o ruido en los datos).

Random Forest es altamente efectivo y generaliza bien en los datos de prueba. Es una buena elecci√≥n para este tipo de problema.

# Mejoras
 - GridSearchCV o RandomizedSearchCV para buscar la mejor combinaci√≥n.

 - Validaci√≥n cruzada (cv=5) para estimar mejor el rendimiento.
 
 - Eliminar o corregir outliers (valores at√≠picos de precio o volumen) que pueden distorsionar el entrenamiento.

 - Aumentar el tama√±o de muestra, si tienes m√°s datos disponibles.

 - Balancear las clases (si el tipo de aguacate est√° muy desbalanceado entre org√°nico y convencional).

## Red Neuronal

MSE (Mean Squared Error) mide el error promedio cuadr√°tico; cuanto menor sea, mejor.
‚Üí 0.0193 indica que el error medio es bajo (buena predicci√≥n promedio).

R¬≤ (Coeficiente de determinaci√≥n) mide cu√°nto de la variabilidad del precio es explicada por el modelo.
‚Üí 0.8765 significa que la red explica el 87.6% de la variaci√≥n del precio promedio, lo cual es muy bueno.

# Efectividad
Random Forest Regressor anterior (R¬≤ ‚âà 0.9084), la red neuronal tiene un desempe√±o ligeramente inferior, pero sigue siendo s√≥lido.

Random Forest	0.908	Mejor generalizaci√≥n, robusto a ruido
Red Neuronal (MLP)	0.877	Buen ajuste, pero podr√≠a mejorarse con tuning

# Mejoras
 - ajustar arquitectura de red 
  - M√°s neuronas o capas ‚Üí (128, 64, 32) o (100, 50)
  - Activaci√≥n 'tanh' si los datos est√°n bien escalados.
  - Regularizaci√≥n: usar alpha=0.001 para evitar sobreajuste.

 - Normalizaci√≥n m√°s precisa, Aunque ya escalaste tus variables, verifica que la media est√© exactamente en 0 y la varianza en 1 (usa StandardScaler() correctamente antes del entrenamiento).

 ## üìä Comparaci√≥n de Modelos de Regresi√≥n

| Modelo | MAE ‚Üì | RMSE ‚Üì | MSE ‚Üì | R¬≤ ‚Üë | Interpretaci√≥n |
|:--------|:-------:|:--------:|:-------:|:------:|:---------------|
| **Regresi√≥n Lineal** | 0.1903 | 0.2490 | 0.0620 | 0.6029 | Modelo base, solo capta relaciones lineales simples. |
| **Random Forest** | 0.0852 | 0.1196 | 0.0143 | 0.9084 | Excelente desempe√±o, capta relaciones no lineales y patrones complejos. |
| **Red Neuronal** | ‚Äî | ‚àö0.0144 ‚âà **0.1200** | 0.0144 | 0.9078 | Rendimiento muy similar a Random Forest, pero ligeramente menor. |

---

## üìà An√°lisis Comparativo

1. **Precisi√≥n (MAE y RMSE):**
   - El **Random Forest** tiene los valores de error m√°s bajos (**MAE = 0.0852**, **RMSE = 0.1196**), lo que indica que sus predicciones se acercan m√°s a los valores reales.
   - La **Red Neuronal** muestra un rendimiento casi id√©ntico (**RMSE ‚âà 0.1200**), lo que confirma su capacidad para capturar relaciones no lineales.
   - La **Regresi√≥n Lineal** presenta un error significativamente mayor, evidenciando que el problema **no es puramente lineal**.

2. **Capacidad explicativa (R¬≤):**
   - Tanto **Random Forest (0.9084)** como la **Red Neuronal (0.9078)** explican m√°s del **90% de la variabilidad** en los datos.
   - La **Regresi√≥n Lineal (0.6029)** solo explica el 60%, quedando como modelo de referencia o l√≠nea base.

3. **Comportamiento general:**
   - El **Random Forest** ofrece un **equilibrio excelente** entre precisi√≥n, estabilidad y facilidad de entrenamiento.
   - La **Red Neuronal** logra un rendimiento competitivo, aunque requiere mayor ajuste y tiempo de entrenamiento.
   - La **Regresi√≥n Lineal** es √∫til para interpretaci√≥n y an√°lisis de coeficientes, pero no para m√°xima precisi√≥n predictiva.

---

## üß† Conclusi√≥n General

> Tras la evaluaci√≥n de los tres modelos de regresi√≥n sobre el dataset de precios de aguacates, se concluye que el **Random Forest** es el modelo con **mejor desempe√±o global**, alcanzando un **R¬≤ de 0.9084**, un **MAE de 0.0852** y un **RMSE de 0.1196**.  
> 
> Esto indica que el modelo explica m√°s del **90% de la variabilidad** en los precios promedio con errores bajos y consistentes.  
> 
> La **Red Neuronal** obtuvo resultados casi equivalentes (R¬≤ = 0.9078), mientras que la **Regresi√≥n Lineal (R¬≤ = 0.6029)** mostr√≥ un rendimiento inferior al no capturar las relaciones no lineales del problema.  
> 
> En conclusi√≥n, el **Random Forest** se posiciona como el modelo m√°s adecuado por su **alta precisi√≥n, robustez y buena capacidad de generalizaci√≥n**, sin requerir ajustes tan complejos como las redes neuronales.
